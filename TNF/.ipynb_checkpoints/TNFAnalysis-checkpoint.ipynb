{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thursday Night Football Twitter Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, I wanted to analyse tweets during a Thursday Night Football game. The game that I choose to gather tweets during was November 9th matchup between the Seattle Seahawks vs. Arizona Cardinals.\n",
    "\n",
    "The hashtags that I used to search twitter were #NFL, #ThursdayNightFootball, #SEAvsAZ, #TNF, #Seahawks, #Cardinals, #WeAre12, #BeRedSeeRed, #BirdGang, #Sea12Hawk.\n",
    "\n",
    "The twitter listener was started at 7:15pm (about 15 minutes before kick-off) and 11:00pm (a few minutes after the game ended)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used a Postgres database to store the tweets and was able to upload the database into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database, save in pandas dataframe\n",
    "conn = psycopg2.connect(\"dbname=twitter user=meutband\")\n",
    "data = pd.read_sql(\"SELECT * FROM nfl\", conn)\n",
    "\n",
    "data.to_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first things that I chose to look into was the language. The NFL is watched by millions of people across the world and they tweet about it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['language'] = data['tweet'].progress_apply(lambda tweet: TextBlob(tweet).detect_language())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of languages tweeted: \", len(data['language'].value_counts()))\n",
    "print(data['language'].value_counts()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below cleans the tweets. Stopwords are removed based on the language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_tweets(df, lang):\n",
    "        \n",
    "    # Tokenize the tweets\n",
    "    tt = TweetTokenizer(strip_handles=True)\n",
    "    df['tweet'] = df['tweet'].apply(tt.tokenize)\n",
    "    \n",
    "    # Remove stopwords    \n",
    "    languages = {'da':'danish', 'en':'english', 'fr':'french', \n",
    "                 'de':'german', 'pt':'portuguese', 'es':'spanish'}\n",
    "    stop = set(stopwords.words(languages[lang]))\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: [item.lower() for item in x if item not in stop])\n",
    "    \n",
    "    # Remove punctuations\n",
    "    punc = \"`~!@#$%^&*()-_=+[]{}\\|;:',<.>/?â€¦\"\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: [item for item in x if item not in punc])\n",
    "    \n",
    "    # Remove link from tweet if result is empty list, then drop row\n",
    "    link = \"https://\"\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: [item for item in x if link not in item])\n",
    "    \n",
    "    # Create columns of all hastages used and remove hashtags from tweet    \n",
    "    df['hashtags'] = df['tweet'].apply(lambda x: [item for item in x if '#' in item])\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: [item for item in x if '#' not in item])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English, Spanish, and Portuguese languages were chosen to filter the datasets based on the number of tweets of each number. (as seen above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes that contains only the 'language' that contain 500 or more tweets\n",
    "\n",
    "english = data.loc[data['language'] == 'en']\n",
    "english = clean_tweets(english, 'en')\n",
    "english = english.reset_index(drop=True)\n",
    "\n",
    "spanish = data.loc[data['language'] == 'es']\n",
    "spanish = clean_tweets(spanish, 'es')\n",
    "spanish = spanish.reset_index(drop=True)\n",
    "\n",
    "portuguese = data.loc[data['language'] == 'pt']\n",
    "portuguese = clean_tweets(portuguese, 'pt')\n",
    "portuguese = portuguese.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portuguese.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating WordClouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below creates the WordCloud image.\n",
    "- The WordCloud function calls for strings as inputs. Therefore the tweets columns needed to be joined together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cloud(df, col='tweet', coll=True):\n",
    "    \n",
    "    # input col to see difference column\n",
    "    # coll input is for collocations parameter inside WordCount\n",
    "        #i.e. Whether to include collocations (bigrams) of two words.\n",
    "    \n",
    "    # join tweets into string\n",
    "    text = ' '.join(df[col].str.join(' '))\n",
    "    \n",
    "    # WordCloud implementation\n",
    "    wc = WordCloud(background_color=\"white\", collocations=coll)\n",
    "    wc.generate(text)\n",
    "    \n",
    "    # Show figure\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(wc)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create clouds for each of the languages chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"English\")\n",
    "cloud(english)\n",
    "print(\"Spanish\")\n",
    "cloud(spanish)\n",
    "print(\"Portuguese\")\n",
    "cloud(portuguese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the WordClouds above, retweets (labeled as 'rt') were a mashive contributor to the counts. In order to minimize the impact of 'rt', I choose to separate retweets from their original tweet.\n",
    "\n",
    "The function below separates into retweets and original tweets.\n",
    "- 'rt' is removed from the tweet once the retweet is separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate dataframes for original tweets and retweets, remove rt from retweets\n",
    "\n",
    "def separate_dataframes(df):\n",
    "\n",
    "    orig = pd.DataFrame(columns=list(df))\n",
    "    ret = pd.DataFrame(columns=list(df))\n",
    "\n",
    "    # if 'rt' in tweet then add to ret df\n",
    "    for i in range(df.shape[0]):\n",
    "        if 'rt' in df['tweet'][i]:\n",
    "            ret = ret.append(df.loc[[i]])\n",
    "        else:\n",
    "            orig = orig.append(df.loc[[i]])\n",
    "    \n",
    "    # remove 'rt' from tweets\n",
    "    ret['tweet'] = ret['tweet'].apply(lambda x: [item for item in x if item != 'rt'])\n",
    "    \n",
    "    return ret, orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create retweet and original dataframes for each language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_ret, eng_or = separate_dataframes(english)\n",
    "sp_ret, sp_or = separate_dataframes(spanish)\n",
    "port_ret, port_or = separate_dataframes(portuguese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"English Retweets\")\n",
    "cloud(eng_ret)\n",
    "print(\"English Originals\")\n",
    "cloud(eng_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Spanish Retweets\")\n",
    "cloud(sp_ret)\n",
    "print(\"Spanish Originals\")\n",
    "cloud(sp_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Portuguese Retweets\")\n",
    "cloud(port_ret)\n",
    "print(\"Portuguse Originals\")\n",
    "cloud(port_or)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating WordClouds, pt 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create WordCloud that shows the usage of hashtags in the tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"English Hastags\")\n",
    "cloud(english, col='hashtags', coll=False)\n",
    "print(\"Spanish Hastags\")\n",
    "cloud(spanish, col='hashtags', coll=False)\n",
    "print(\"Portuguese Hastags\")\n",
    "cloud(portuguese, col='hashtags', coll=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
